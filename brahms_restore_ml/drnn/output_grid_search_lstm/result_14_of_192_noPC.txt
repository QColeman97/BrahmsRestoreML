905449.4375
VAL LOSS ^
791921.125
LOSS ^
{"layers": [{"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [3349422.5, 2621467.5, 2069146.375, 1751427.0, 1509961.375, 1345541.75, 1204964.875, 1084866.5, 998449.375, 905449.4375]}
VAL LOSS FACTORS ^
{"layers": [{"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [6765345.5, 2996709.25, 2280016.25, 1837513.375, 1538279.875, 1307932.875, 1151356.0, 1010917.0625, 899379.9375, 791921.125]}
LOSS FACTORS^
