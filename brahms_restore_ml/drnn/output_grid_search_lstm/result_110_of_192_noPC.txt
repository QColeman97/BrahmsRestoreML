1318651.25
VAL LOSS ^
1229615.25
LOSS ^
{"layers": [{"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 16, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [4273751.0, 3177289.75, 2676704.75, 2309376.0, 2042329.625, 1821040.125, 1655423.75, 1533833.25, 1417374.375, 1318651.25]}
VAL LOSS FACTORS ^
{"layers": [{"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "LSTM", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 16, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [9561589.0, 3732618.75, 2889553.75, 2455209.25, 2102261.75, 1852197.0, 1640561.375, 1477188.25, 1345384.5, 1229615.25]}
LOSS FACTORS^
