1273410.25
VAL LOSS ^
1996247.125
LOSS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "RMSprop", "clip value": null, "learning rate": 0.0001, "all_loss": [3502861.75, 2748243.0, 2562768.0, 2201712.0, 1960266.5, 1779370.25, 1711649.0, 1565966.25, 1472735.0, 1273410.25]}
VAL LOSS FACTORS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "RMSprop", "clip value": null, "learning rate": 0.0001, "all_loss": [7738260.5, 3634185.5, 3179554.75, 2850215.5, 2657745.5, 2458584.0, 2352537.25, 2189177.75, 2080513.375, 1996247.125]}
LOSS FACTORS^
