510744.3125
VAL LOSS ^
1493102.625
LOSS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": true, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": null, "learning rate": 0.0001, "all_loss": [3683983.25, 2545273.0, 1929279.25, 1502754.75, 1231417.25, 1014482.6875, 816563.375, 773170.25, 702276.4375, 510744.3125]}
VAL LOSS FACTORS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": true, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": null, "learning rate": 0.0001, "all_loss": [8110601.0, 3846933.25, 3088477.75, 2595822.5, 2258032.25, 2028672.0, 1889161.625, 1756550.875, 1617868.625, 1493102.625]}
LOSS FACTORS^
