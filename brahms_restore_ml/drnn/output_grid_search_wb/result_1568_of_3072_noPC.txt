1244700.875
VAL LOSS ^
1610237.875
LOSS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 16, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [3942936.0, 3360373.5, 2864264.0, 2469275.75, 1841473.625, 1662440.25, 1811417.375, 1770719.0, 1329934.0, 1244700.875]}
VAL LOSS FACTORS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 16, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [10541769.0, 4227780.5, 3552161.75, 3054212.25, 2320956.0, 2036026.125, 1928434.625, 1831105.75, 1684798.75, 1610237.875]}
LOSS FACTORS^
