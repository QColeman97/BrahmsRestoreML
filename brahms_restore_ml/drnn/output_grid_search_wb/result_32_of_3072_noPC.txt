915391.125
VAL LOSS ^
1475918.125
LOSS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [3683250.75, 2665743.0, 1622161.75, 1561275.5, 1314124.25, 1178890.0, 1111806.125, 988536.25, 955039.1875, 915391.125]}
VAL LOSS FACTORS ^
{"layers": [{"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "RNN", "nrn_div": 2, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 8, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": 10, "learning rate": 0.001, "all_loss": [7578407.0, 3581547.5, 2362495.75, 1914913.375, 1931151.625, 1773438.25, 1625367.5, 1584262.25, 1509659.875, 1475918.125]}
LOSS FACTORS^
