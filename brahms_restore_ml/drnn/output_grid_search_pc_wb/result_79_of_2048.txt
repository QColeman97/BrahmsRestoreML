88434568.0
VAL LOSS ^
84143520.0
LOSS ^
{"layers": [{"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 1, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": -1, "learning rate": 0.0001, "all_loss": [90012784.0, 89061864.0, 88849016.0, 88746848.0, 88680224.0, 88632080.0, 88562288.0, 88518848.0, 88479680.0, 88434568.0]}
VAL LOSS FACTORS ^
{"layers": [{"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": true, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 1, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": -1, "learning rate": 0.0001, "all_loss": [104276400.0, 86461528.0, 85406136.0, 85029256.0, 84762376.0, 84562848.0, 84431664.0, 84336456.0, 84231664.0, 84143520.0]}
LOSS FACTORS^
