74128488.0
VAL LOSS ^
82943576.0
LOSS ^
{"layers": [{"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": true, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 3, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": -1, "learning rate": 0.0001, "all_loss": [88270848.0, 80316984.0, 78828720.0, 78070376.0, 77679744.0, 77068208.0, 76156920.0, 75477320.0, 75223040.0, 74128488.0]}
VAL LOSS FACTORS ^
{"layers": [{"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": true, "bias_rnn": true, "bias_dense": true, "bidir": true, "rnn_dropout": [0.0, 0.0], "bn": false, "batch_size": 3, "epochs": 10, "gamma": 0.1, "optimizer": "Adam", "clip value": -1, "learning rate": 0.0001, "all_loss": [115637376.0, 93240288.0, 88353168.0, 87036688.0, 86612296.0, 85727104.0, 84949392.0, 84065536.0, 83359280.0, 82943576.0]}
LOSS FACTORS^
