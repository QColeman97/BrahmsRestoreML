92428920.0
VAL LOSS ^
96309736.0
LOSS ^
{"layers": [{"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 3, "epochs": 10, "gamma": 0.05, "optimizer": "Adam", "clip value": -1, "learning rate": 0.0001, "all_loss": [98477224.0, 94143560.0, 92927440.0, 92629384.0, 92604112.0, 92563208.0, 92517576.0, 92481344.0, 92455736.0, 92428920.0]}
VAL LOSS FACTORS ^
{"layers": [{"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "RNN", "nrn_div": 4, "act": "relu"}, {"type": "Dense", "nrn_div": 1, "act": null}], "scale": false, "rnn_res_cntn": false, "bias_rnn": true, "bias_dense": true, "bidir": false, "rnn_dropout": [0.25, 0.25], "bn": false, "batch_size": 3, "epochs": 10, "gamma": 0.05, "optimizer": "Adam", "clip value": -1, "learning rate": 0.0001, "all_loss": [127687336.0, 103590184.0, 99006432.0, 97608200.0, 97042576.0, 96814480.0, 96627064.0, 96508368.0, 96394288.0, 96309736.0]}
LOSS FACTORS^
